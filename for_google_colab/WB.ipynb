{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nwvNgGbYKSE",
        "outputId": "35be393c-bc38-434f-adc0-f526d1716e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SparseConvMIL'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 78 (delta 16), reused 65 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (78/78), 15.84 MiB | 21.07 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MarvinLer/SparseConvMIL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SparseConvMIL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW3YwTA_YYeM",
        "outputId": "e590591b-64f5-44c0-e444-68916de4ba98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SparseConvMIL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv\n",
        "!virtualenv -p python3 venv\n",
        "!source venv/bin/activate && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEmLikDaYbDo",
        "outputId": "59c10376-faca-4a0c-a0b4-0902cd762ba0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.13.4)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.2.0)\n",
            "Installing collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.8 virtualenv-20.25.1\n",
            "created virtual environment CPython3.10.12.final.0-64 in 907ms\n",
            "  creator CPython3Posix(dest=/content/SparseConvMIL/venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==24.0, setuptools==69.1.0, wheel==0.42.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
            "Collecting torch (from -r requirements.txt (line 1))\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision (from -r requirements.txt (line 2))\n",
            "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting numpy (from -r requirements.txt (line 3))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn (from -r requirements.txt (line 4))\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting filelock (from torch->-r requirements.txt (line 1))\n",
            "  Downloading filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch->-r requirements.txt (line 1))\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch->-r requirements.txt (line 1))\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting fsspec (from torch->-r requirements.txt (line 1))\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->-r requirements.txt (line 2))\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn->-r requirements.txt (line 4))\n",
            "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 4))\n",
            "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r requirements.txt (line 4))\n",
            "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->-r requirements.txt (line 1))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mpmath>=0.19 (from sympy->torch->-r requirements.txt (line 1))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
            "Downloading filelock-3.13.4-py3-none-any.whl (11 kB)\n",
            "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, threadpoolctl, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, fsspec, filelock, triton, scipy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, scikit-learn, nvidia-cusolver-cu12, torch, torchvision\n",
            "Successfully installed MarkupSafe-2.1.5 filelock-3.13.4 fsspec-2024.3.1 jinja2-3.1.3 joblib-1.4.0 mpmath-1.3.0 networkx-3.3 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pillow-10.3.0 scikit-learn-1.4.2 scipy-1.13.0 sympy-1.12 threadpoolctl-3.4.0 torch-2.2.2 torchvision-0.17.2 triton-2.2.0 typing-extensions-4.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "!git clone https://github.com/facebookresearch/SparseConvNet.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRJBRKq8ZbOq",
        "outputId": "88e9216e-a99a-4a01-e721-3deba7d90362"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'SparseConvNet'...\n",
            "remote: Enumerating objects: 1952, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 1952 (delta 39), reused 39 (delta 17), pack-reused 1880\u001b[K\n",
            "Receiving objects: 100% (1952/1952), 921.93 KiB | 3.41 MiB/s, done.\n",
            "Resolving deltas: 100% (1388/1388), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SparseConvNet/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nbc1xPGZjKx",
        "outputId": "8e359133-94b3-425f-b130-aacf7c8b9c11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SparseConvNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash develop.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5XeYXRPZk8n",
        "outputId": "c5aec64b-a248-4477-85af-6e7b8b48f9c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating sparseconvnet.egg-info\n",
            "writing sparseconvnet.egg-info/PKG-INFO\n",
            "writing dependency_links to sparseconvnet.egg-info/dependency_links.txt\n",
            "writing top-level names to sparseconvnet.egg-info/top_level.txt\n",
            "writing manifest file 'sparseconvnet.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'sparseconvnet.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'sparseconvnet.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:415: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:425: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'sparseconvnet.SCN' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/sparseconvnet\n",
            "creating build/temp.linux-x86_64-cpython-310/sparseconvnet/SCN\n",
            "/usr/local/cuda/bin/nvcc -I/content/SparseConvNet/sparseconvnet/SCN/ -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c sparseconvnet/SCN/cuda.cu -o build/temp.linux-x86_64-cpython-310/sparseconvnet/SCN/cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -std=c++17 -Xcompiler -fopenmp -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=SCN -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/SparseConvNet/sparseconvnet/SCN/ -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c sparseconvnet/SCN/pybind.cpp -o build/temp.linux-x86_64-cpython-310/sparseconvnet/SCN/pybind.o -std=c++17 -fopenmp -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=SCN -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/Exceptions.h:14\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/python.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:7\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘\u001b[01m\u001b[Kclass pybind11::class_<Metadata<1> >\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:12:13:\u001b[m\u001b[K   required from ‘\u001b[01m\u001b[Kvoid dimension(pybind11::module&, const char*) [with int Dimension = 1; pybind11::module = pybind11::module_]\u001b[m\u001b[K’\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:204:15:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h:1496:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::class_<Metadata<1> >\u001b[m\u001b[K’ declared with greater visibility than its base ‘\u001b[01m\u001b[Kpybind11::detail::generic_type\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wattributes\u0007-Wattributes\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            " 1496 | class \u001b[01;35m\u001b[Kclass_\u001b[m\u001b[K : public detail::generic_type {\n",
            "      |       \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘\u001b[01m\u001b[Kclass pybind11::class_<Metadata<2> >\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:12:13:\u001b[m\u001b[K   required from ‘\u001b[01m\u001b[Kvoid dimension(pybind11::module&, const char*) [with int Dimension = 2; pybind11::module = pybind11::module_]\u001b[m\u001b[K’\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:205:15:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h:1496:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::class_<Metadata<2> >\u001b[m\u001b[K’ declared with greater visibility than its base ‘\u001b[01m\u001b[Kpybind11::detail::generic_type\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wattributes\u0007-Wattributes\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘\u001b[01m\u001b[Kclass pybind11::class_<Metadata<3> >\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:12:13:\u001b[m\u001b[K   required from ‘\u001b[01m\u001b[Kvoid dimension(pybind11::module&, const char*) [with int Dimension = 3; pybind11::module = pybind11::module_]\u001b[m\u001b[K’\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:206:15:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h:1496:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::class_<Metadata<3> >\u001b[m\u001b[K’ declared with greater visibility than its base ‘\u001b[01m\u001b[Kpybind11::detail::generic_type\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wattributes\u0007-Wattributes\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘\u001b[01m\u001b[Kclass pybind11::class_<Metadata<4> >\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:12:13:\u001b[m\u001b[K   required from ‘\u001b[01m\u001b[Kvoid dimension(pybind11::module&, const char*) [with int Dimension = 4; pybind11::module = pybind11::module_]\u001b[m\u001b[K’\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:207:15:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h:1496:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::class_<Metadata<4> >\u001b[m\u001b[K’ declared with greater visibility than its base ‘\u001b[01m\u001b[Kpybind11::detail::generic_type\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wattributes\u0007-Wattributes\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘\u001b[01m\u001b[Kclass pybind11::class_<Metadata<5> >\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:12:13:\u001b[m\u001b[K   required from ‘\u001b[01m\u001b[Kvoid dimension(pybind11::module&, const char*) [with int Dimension = 5; pybind11::module = pybind11::module_]\u001b[m\u001b[K’\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:208:15:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h:1496:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::class_<Metadata<5> >\u001b[m\u001b[K’ declared with greater visibility than its base ‘\u001b[01m\u001b[Kpybind11::detail::generic_type\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wattributes\u0007-Wattributes\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘\u001b[01m\u001b[Kclass pybind11::class_<Metadata<6> >\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:12:13:\u001b[m\u001b[K   required from ‘\u001b[01m\u001b[Kvoid dimension(pybind11::module&, const char*) [with int Dimension = 6; pybind11::module = pybind11::module_]\u001b[m\u001b[K’\n",
            "\u001b[01m\u001b[Ksparseconvnet/SCN/pybind.cpp:209:15:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/pybind11/pybind11.h:1496:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::class_<Metadata<6> >\u001b[m\u001b[K’ declared with greater visibility than its base ‘\u001b[01m\u001b[Kpybind11::detail::generic_type\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wattributes\u0007-Wattributes\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/SparseConvNet/sparseconvnet/SCN/ -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c sparseconvnet/SCN/sparseconvnet_cuda.cpp -o build/temp.linux-x86_64-cpython-310/sparseconvnet/SCN/sparseconvnet_cuda.o -std=c++17 -fopenmp -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=SCN -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/sparseconvnet\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/sparseconvnet/SCN/cuda.o build/temp.linux-x86_64-cpython-310/sparseconvnet/SCN/pybind.o build/temp.linux-x86_64-cpython-310/sparseconvnet/SCN/sparseconvnet_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/sparseconvnet/SCN.cpython-310-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-310/sparseconvnet/SCN.cpython-310-x86_64-linux-gnu.so -> sparseconvnet\n",
            "Creating /usr/local/lib/python3.10/dist-packages/sparseconvnet.egg-link (link to .)\n",
            "Adding sparseconvnet 0.2 to easy-install.pth file\n",
            "\n",
            "Installed /content/SparseConvNet\n",
            "Processing dependencies for sparseconvnet==0.2\n",
            "Finished processing dependencies for sparseconvnet==0.2\n",
            "Using CUDA.\n",
            "Input SparseConvNetTensor: SparseConvNetTensor<<features=tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0'),features.shape=torch.Size([132, 1]),batch_locations=tensor([[ 0,  1,  0],\n",
            "        [ 0,  5,  0],\n",
            "        [ 0,  8,  0],\n",
            "        [ 0,  9,  0],\n",
            "        [ 0, 10,  0],\n",
            "        [ 0, 13,  0],\n",
            "        [ 0, 18,  0],\n",
            "        [ 0, 23,  0],\n",
            "        [ 0, 24,  0],\n",
            "        [ 0, 30,  0],\n",
            "        [ 0, 38,  0],\n",
            "        [ 0, 42,  0],\n",
            "        [ 0, 43,  0],\n",
            "        [ 0, 47,  0],\n",
            "        [ 0, 48,  0],\n",
            "        [ 0, 49,  0],\n",
            "        [ 0, 53,  0],\n",
            "        [ 0, 58,  0],\n",
            "        [ 0, 59,  0],\n",
            "        [ 0, 60,  0],\n",
            "        [ 1,  1,  0],\n",
            "        [ 1,  5,  0],\n",
            "        [ 1,  8,  0],\n",
            "        [ 1, 13,  0],\n",
            "        [ 1, 18,  0],\n",
            "        [ 1, 22,  0],\n",
            "        [ 1, 25,  0],\n",
            "        [ 1, 30,  0],\n",
            "        [ 1, 38,  0],\n",
            "        [ 1, 41,  0],\n",
            "        [ 1, 44,  0],\n",
            "        [ 1, 47,  0],\n",
            "        [ 1, 50,  0],\n",
            "        [ 1, 53,  0],\n",
            "        [ 1, 58,  0],\n",
            "        [ 1, 61,  0],\n",
            "        [ 2,  1,  0],\n",
            "        [ 2,  2,  0],\n",
            "        [ 2,  3,  0],\n",
            "        [ 2,  4,  0],\n",
            "        [ 2,  5,  0],\n",
            "        [ 2,  8,  0],\n",
            "        [ 2,  9,  0],\n",
            "        [ 2, 13,  0],\n",
            "        [ 2, 18,  0],\n",
            "        [ 2, 22,  0],\n",
            "        [ 2, 25,  0],\n",
            "        [ 2, 30,  0],\n",
            "        [ 2, 34,  0],\n",
            "        [ 2, 38,  0],\n",
            "        [ 2, 41,  0],\n",
            "        [ 2, 44,  0],\n",
            "        [ 2, 47,  0],\n",
            "        [ 2, 48,  0],\n",
            "        [ 2, 49,  0],\n",
            "        [ 2, 53,  0],\n",
            "        [ 2, 58,  0],\n",
            "        [ 2, 62,  0],\n",
            "        [ 3,  1,  0],\n",
            "        [ 3,  5,  0],\n",
            "        [ 3,  8,  0],\n",
            "        [ 3, 13,  0],\n",
            "        [ 3, 18,  0],\n",
            "        [ 3, 22,  0],\n",
            "        [ 3, 25,  0],\n",
            "        [ 3, 31,  0],\n",
            "        [ 3, 33,  0],\n",
            "        [ 3, 35,  0],\n",
            "        [ 3, 37,  0],\n",
            "        [ 3, 41,  0],\n",
            "        [ 3, 44,  0],\n",
            "        [ 3, 47,  0],\n",
            "        [ 3, 50,  0],\n",
            "        [ 3, 53,  0],\n",
            "        [ 3, 58,  0],\n",
            "        [ 3, 61,  0],\n",
            "        [ 4,  1,  0],\n",
            "        [ 4,  5,  0],\n",
            "        [ 4,  8,  0],\n",
            "        [ 4,  9,  0],\n",
            "        [ 4, 10,  0],\n",
            "        [ 4, 13,  0],\n",
            "        [ 4, 14,  0],\n",
            "        [ 4, 15,  0],\n",
            "        [ 4, 18,  0],\n",
            "        [ 4, 19,  0],\n",
            "        [ 4, 20,  0],\n",
            "        [ 4, 23,  0],\n",
            "        [ 4, 24,  0],\n",
            "        [ 4, 32,  0],\n",
            "        [ 4, 36,  0],\n",
            "        [ 4, 42,  0],\n",
            "        [ 4, 43,  0],\n",
            "        [ 4, 47,  0],\n",
            "        [ 4, 50,  0],\n",
            "        [ 4, 53,  0],\n",
            "        [ 4, 54,  0],\n",
            "        [ 4, 55,  0],\n",
            "        [ 4, 58,  0],\n",
            "        [ 4, 59,  0],\n",
            "        [ 4, 60,  0],\n",
            "        [ 0,  1,  1],\n",
            "        [ 0,  2,  1],\n",
            "        [ 0,  3,  1],\n",
            "        [ 0, 18,  1],\n",
            "        [ 0, 19,  1],\n",
            "        [ 0, 20,  1],\n",
            "        [ 0, 21,  1],\n",
            "        [ 0, 22,  1],\n",
            "        [ 1,  1,  1],\n",
            "        [ 1,  4,  1],\n",
            "        [ 1,  7,  1],\n",
            "        [ 1, 11,  1],\n",
            "        [ 1, 12,  1],\n",
            "        [ 1, 13,  1],\n",
            "        [ 1, 21,  1],\n",
            "        [ 2,  1,  1],\n",
            "        [ 2,  2,  1],\n",
            "        [ 2,  3,  1],\n",
            "        [ 2, 20,  1],\n",
            "        [ 3,  1,  1],\n",
            "        [ 3,  7,  1],\n",
            "        [ 3, 11,  1],\n",
            "        [ 3, 12,  1],\n",
            "        [ 3, 13,  1],\n",
            "        [ 3, 21,  1],\n",
            "        [ 4,  1,  1],\n",
            "        [ 4,  7,  1],\n",
            "        [ 4, 18,  1],\n",
            "        [ 4, 19,  1],\n",
            "        [ 4, 20,  1],\n",
            "        [ 4, 21,  1]]),batch_locations.shape=torch.Size([132, 3]),spatial size=tensor([87, 87])>>\n",
            "Output SparseConvNetTensor: tensor([[[[1.6000, 0.6629, -0.0000,  ..., 0.0946, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[-0.0000, 1.3866, 0.7602,  ..., 1.1933, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.5561, -0.0000, 0.4136,  ..., 2.0327, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000, -0.0000, 0.1354,  ..., -0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.4140, 0.0519, 0.5810,  ..., -0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.6230, -0.0000, 0.3004,  ..., 0.6676, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.6395, 0.3372, 1.3940,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[-0.0000, -0.0000, 0.4832,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0961, -0.0000, 0.7641,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000, -0.0000, -0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0761, -0.0000, -0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.9146, 0.0052, 0.0035,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
            "       device='cuda:0', grad_fn=<SparseToDenseFunctionBackward>)\n",
            "Input SparseConvNetTensor: SparseConvNetTensor<<features=tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0'),features.shape=torch.Size([132, 1]),batch_locations=tensor([[ 0,  1,  0],\n",
            "        [ 0,  5,  0],\n",
            "        [ 0,  8,  0],\n",
            "        [ 0,  9,  0],\n",
            "        [ 0, 10,  0],\n",
            "        [ 0, 13,  0],\n",
            "        [ 0, 18,  0],\n",
            "        [ 0, 23,  0],\n",
            "        [ 0, 24,  0],\n",
            "        [ 0, 30,  0],\n",
            "        [ 0, 38,  0],\n",
            "        [ 0, 42,  0],\n",
            "        [ 0, 43,  0],\n",
            "        [ 0, 47,  0],\n",
            "        [ 0, 48,  0],\n",
            "        [ 0, 49,  0],\n",
            "        [ 0, 53,  0],\n",
            "        [ 0, 58,  0],\n",
            "        [ 0, 59,  0],\n",
            "        [ 0, 60,  0],\n",
            "        [ 1,  1,  0],\n",
            "        [ 1,  5,  0],\n",
            "        [ 1,  8,  0],\n",
            "        [ 1, 13,  0],\n",
            "        [ 1, 18,  0],\n",
            "        [ 1, 22,  0],\n",
            "        [ 1, 25,  0],\n",
            "        [ 1, 30,  0],\n",
            "        [ 1, 38,  0],\n",
            "        [ 1, 41,  0],\n",
            "        [ 1, 44,  0],\n",
            "        [ 1, 47,  0],\n",
            "        [ 1, 50,  0],\n",
            "        [ 1, 53,  0],\n",
            "        [ 1, 58,  0],\n",
            "        [ 1, 61,  0],\n",
            "        [ 2,  1,  0],\n",
            "        [ 2,  2,  0],\n",
            "        [ 2,  3,  0],\n",
            "        [ 2,  4,  0],\n",
            "        [ 2,  5,  0],\n",
            "        [ 2,  8,  0],\n",
            "        [ 2,  9,  0],\n",
            "        [ 2, 13,  0],\n",
            "        [ 2, 18,  0],\n",
            "        [ 2, 22,  0],\n",
            "        [ 2, 25,  0],\n",
            "        [ 2, 30,  0],\n",
            "        [ 2, 34,  0],\n",
            "        [ 2, 38,  0],\n",
            "        [ 2, 41,  0],\n",
            "        [ 2, 44,  0],\n",
            "        [ 2, 47,  0],\n",
            "        [ 2, 48,  0],\n",
            "        [ 2, 49,  0],\n",
            "        [ 2, 53,  0],\n",
            "        [ 2, 58,  0],\n",
            "        [ 2, 62,  0],\n",
            "        [ 3,  1,  0],\n",
            "        [ 3,  5,  0],\n",
            "        [ 3,  8,  0],\n",
            "        [ 3, 13,  0],\n",
            "        [ 3, 18,  0],\n",
            "        [ 3, 22,  0],\n",
            "        [ 3, 25,  0],\n",
            "        [ 3, 31,  0],\n",
            "        [ 3, 33,  0],\n",
            "        [ 3, 35,  0],\n",
            "        [ 3, 37,  0],\n",
            "        [ 3, 41,  0],\n",
            "        [ 3, 44,  0],\n",
            "        [ 3, 47,  0],\n",
            "        [ 3, 50,  0],\n",
            "        [ 3, 53,  0],\n",
            "        [ 3, 58,  0],\n",
            "        [ 3, 61,  0],\n",
            "        [ 4,  1,  0],\n",
            "        [ 4,  5,  0],\n",
            "        [ 4,  8,  0],\n",
            "        [ 4,  9,  0],\n",
            "        [ 4, 10,  0],\n",
            "        [ 4, 13,  0],\n",
            "        [ 4, 14,  0],\n",
            "        [ 4, 15,  0],\n",
            "        [ 4, 18,  0],\n",
            "        [ 4, 19,  0],\n",
            "        [ 4, 20,  0],\n",
            "        [ 4, 23,  0],\n",
            "        [ 4, 24,  0],\n",
            "        [ 4, 32,  0],\n",
            "        [ 4, 36,  0],\n",
            "        [ 4, 42,  0],\n",
            "        [ 4, 43,  0],\n",
            "        [ 4, 47,  0],\n",
            "        [ 4, 50,  0],\n",
            "        [ 4, 53,  0],\n",
            "        [ 4, 54,  0],\n",
            "        [ 4, 55,  0],\n",
            "        [ 4, 58,  0],\n",
            "        [ 4, 59,  0],\n",
            "        [ 4, 60,  0],\n",
            "        [ 0,  1,  1],\n",
            "        [ 0,  2,  1],\n",
            "        [ 0,  3,  1],\n",
            "        [ 0, 18,  1],\n",
            "        [ 0, 19,  1],\n",
            "        [ 0, 20,  1],\n",
            "        [ 0, 21,  1],\n",
            "        [ 0, 22,  1],\n",
            "        [ 1,  1,  1],\n",
            "        [ 1,  4,  1],\n",
            "        [ 1,  7,  1],\n",
            "        [ 1, 11,  1],\n",
            "        [ 1, 12,  1],\n",
            "        [ 1, 13,  1],\n",
            "        [ 1, 21,  1],\n",
            "        [ 2,  1,  1],\n",
            "        [ 2,  2,  1],\n",
            "        [ 2,  3,  1],\n",
            "        [ 2, 20,  1],\n",
            "        [ 3,  1,  1],\n",
            "        [ 3,  7,  1],\n",
            "        [ 3, 11,  1],\n",
            "        [ 3, 12,  1],\n",
            "        [ 3, 13,  1],\n",
            "        [ 3, 21,  1],\n",
            "        [ 4,  1,  1],\n",
            "        [ 4,  7,  1],\n",
            "        [ 4, 18,  1],\n",
            "        [ 4, 19,  1],\n",
            "        [ 4, 20,  1],\n",
            "        [ 4, 21,  1]]),batch_locations.shape=torch.Size([132, 3]),spatial size=tensor([87, 87])>>\n",
            "Output SparseConvNetTensor: tensor([[[[1.6000, 0.6629, -0.0000,  ..., 0.0946, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[-0.0000, 1.3866, 0.7602,  ..., 1.1933, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.5561, -0.0000, 0.4136,  ..., 2.0327, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000, -0.0000, 0.1354,  ..., -0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.4140, 0.0519, 0.5810,  ..., -0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.6230, -0.0000, 0.3004,  ..., 0.6676, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.6395, 0.3372, 1.3940,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[-0.0000, -0.0000, 0.4832,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0961, -0.0000, 0.7641,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000, -0.0000, -0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0761, -0.0000, -0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.9146, 0.0052, 0.0035,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
            "       device='cuda:0', grad_fn=<SparseToDenseFunctionBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/SparseConvMIL')\n",
        "import sys\n",
        "sys.path.append('/content/SparseConvMIL')"
      ],
      "metadata": {
        "id": "taDz1z23bFSI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m training --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTLEds7AbIbt",
        "outputId": "e66c897b-5817-41a6-f22a-9816d47f32b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: training.py [-h] [--slide-parent-folder PATH] [--slide-labels-filepath PATH] [--epochs N]\n",
            "                   [--lr LR] [--reg R] [--tile-embedder [MODEL ...]] [--tile-embedder-pretrained]\n",
            "                   [--sparse-conv-n-channels-conv1 SPARSE_CONV_N_CHANNELS_CONV1]\n",
            "                   [--sparse-conv-n-channels-conv2 SPARSE_CONV_N_CHANNELS_CONV2]\n",
            "                   [--sparse-map-downsample SPARSE_MAP_DOWNSAMPLE]\n",
            "                   [--wsi-embedding-classifier-n-inner-neurons WSI_EMBEDDING_CLASSIFIER_N_INNER_NEURONS]\n",
            "                   [--batch-size SIZE] [--n-tiles-per-wsi SIZE] [--j N_WORKERS]\n",
            "\n",
            "SparseConvMIL: Sparse Convolutional Context-Aware Multiple Instance Learning for Whole Slide Image\n",
            "Classification\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --slide-parent-folder PATH\n",
            "                        path of parent folder containing preprocessed slides data\n",
            "  --slide-labels-filepath PATH\n",
            "                        path of CSV-file containing slide labels\n",
            "  --epochs N            number of training epochs\n",
            "  --lr LR               learning rate\n",
            "  --reg R               weight decay\n",
            "  --tile-embedder [MODEL ...]\n",
            "                        type of resnet architecture for the tile embedder\n",
            "  --tile-embedder-pretrained\n",
            "                        use Imagenet-pretrained tile embedder architecture\n",
            "  --sparse-conv-n-channels-conv1 SPARSE_CONV_N_CHANNELS_CONV1\n",
            "                        number of channels of first convolution of the sparse-input CNN pooling\n",
            "  --sparse-conv-n-channels-conv2 SPARSE_CONV_N_CHANNELS_CONV2\n",
            "                        number of channels of first convolution of the sparse-input CNN pooling\n",
            "  --sparse-map-downsample SPARSE_MAP_DOWNSAMPLE\n",
            "                        downsampling factor of the sparse map\n",
            "  --wsi-embedding-classifier-n-inner-neurons WSI_EMBEDDING_CLASSIFIER_N_INNER_NEURONS\n",
            "                        number of inner neurons for the WSI embedding classifier\n",
            "  --batch-size SIZE     number of slides sampled per iteration\n",
            "  --n-tiles-per-wsi SIZE\n",
            "                        number of tiles to be sampled per WSI\n",
            "  --j N_WORKERS         number of workers for dataloader\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/SparseConvMIL\")"
      ],
      "metadata": {
        "id": "3kcBBh1bdSTe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/m24jeczen/Warsztaty-badawcze.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSw2HJVSbLWK",
        "outputId": "cccd7336-796a-4488-905b-8c27cab684e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Warsztaty-badawcze'...\n",
            "remote: Enumerating objects: 2817, done.\u001b[K\n",
            "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 2817 (delta 30), reused 177 (delta 19), pack-reused 2615\u001b[K\n",
            "Receiving objects: 100% (2817/2817), 229.78 MiB | 34.13 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "Updating files: 100% (2787/2787), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nasze dane-trenowanie"
      ],
      "metadata": {
        "id": "ZrQpt42cdWvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"This DataLoader will create.*\")\n"
      ],
      "metadata": {
        "id": "FMGsFFEKe0iy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mtr-TpRddY2y",
        "outputId": "f5c665d0-d38f-4924-ef7a-31fa5ebad6a6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data\n",
            "Length of slide_folders_ids: 58\n",
            "Length of tiles_locations: 58\n",
            "Length of tiles_paths: 58\n",
            "slide_folders_ids: ['ytma49_042403_benign1_ccd', 'ytma49_072303_benign2_ccd', 'ytma49_111303_benign2_ccd', 'ytma49_042003_malignant3_ccd', 'ytma49_111003_malignant2_ccd', 'ytma49_111303_malignant1_ccd', 'ytma49_042203_malignant2_ccd', 'ytma49_042003_benign1_ccd', 'ytma49_111003_benign2_ccd', 'ytma49_111003_benign3_ccd', 'ytma12_010804_malignant3_ccd', 'ytma49_042203_malignant3_ccd', 'ytma49_042403_benign2_ccd', 'ytma23_022103_malignant1_ccd', 'ytma49_111003_malignant1_ccd', 'ytma49_042403_malignant1_ccd', 'ytma10_010704_malignant1_ccd', 'ytma49_042003_malignant1_ccd', 'ytma49_042403_benign3_ccd', 'ytma49_042203_malignant1_ccd', 'ytma49_042003_benign3_ccd', 'ytma49_042003_benign2_ccd', 'ytma23_022103_benign2_ccd', 'ytma55_030603_benign2_ccd', 'ytma12_010804_benign2_ccd', 'ytma55_030603_benign4_ccd', 'ytma10_010704_malignant3_ccd', 'ytma49_042403_malignant2_ccd', 'ytma12_010804_benign3_ccd', 'ytma10_010704_benign2_ccd', 'ytma10_010704_benign3_ccd', 'ytma49_072303_malignant2_ccd', 'ytma49_042203_benign3_ccd', 'ytma49_042403_malignant3_ccd', 'ytma49_072303_malignant1_ccd', 'ytma49_042203_benign2_ccd', 'ytma49_111003_malignant3_ccd', 'ytma49_111303_benign3_ccd', 'ytma49_042003_malignant2_ccd', 'ytma23_022103_benign3_ccd', 'ytma23_022103_malignant2_ccd', 'ytma49_042203_benign1_ccd', 'ytma55_030603_benign5_ccd', 'ytma12_010804_benign1_ccd', 'ytma49_111003_benign1_ccd', 'ytma49_111303_malignant2_ccd', 'ytma10_010704_benign1_ccd', 'ytma23_022103_malignant3_ccd', 'ytma55_030603_benign1_ccd', 'ytma23_022103_benign1_ccd', 'ytma55_030603_benign3_ccd', 'ytma55_030603_benign6_ccd', 'ytma49_111303_benign1_ccd', 'ytma49_111303_malignant3_ccd', 'ytma12_010804_malignant1_ccd', 'ytma12_010804_malignant2_ccd', 'ytma49_072303_benign1_ccd', 'ytma10_010704_malignant2_ccd']\n",
            "tiles_locations: [[[1, 4], [3, 1], [1, 3], [2, 3], [0, 6]], [[6, 4], [4, 2], [5, 5], [0, 3], [6, 6]], [[2, 4], [6, 3], [1, 5], [4, 4], [2, 3]], [[4, 6], [4, 5], [2, 1], [3, 1], [3, 6]], [[0, 1], [1, 4], [4, 2], [1, 1], [1, 3]], [[4, 5], [1, 1], [5, 5], [0, 3], [6, 1]], [[3, 2], [6, 4], [3, 1], [6, 2], [1, 3]], [[1, 5], [4, 4], [1, 1], [1, 6], [0, 3]], [[4, 6], [1, 4], [2, 1], [5, 2], [5, 1]], [[0, 1], [1, 5], [5, 3], [1, 3], [4, 1]], [[6, 4], [0, 2], [3, 3], [3, 6], [1, 2]], [[4, 5], [2, 1], [6, 2], [5, 2], [5, 3]], [[2, 5], [2, 2], [6, 4], [5, 3], [5, 1]], [[0, 1], [3, 3], [4, 3], [3, 6], [1, 6]], [[4, 6], [5, 6], [1, 4], [2, 3], [5, 1]], [[3, 2], [4, 5], [0, 2], [3, 4], [3, 3]], [[3, 4], [1, 1], [1, 2], [2, 6], [2, 3]], [[4, 6], [2, 5], [3, 3], [5, 4], [1, 2]], [[2, 2], [3, 2], [4, 5], [2, 3], [6, 1]], [[3, 2], [1, 4], [3, 1], [5, 3], [0, 4]], [[3, 4], [3, 6], [6, 5], [4, 4], [1, 6]], [[3, 5], [3, 1], [1, 5], [5, 3], [0, 3]], [[4, 6], [2, 5], [1, 4], [3, 3], [2, 3]], [[4, 6], [6, 2], [3, 4], [4, 4], [5, 5]], [[2, 4], [0, 5], [2, 1], [6, 2], [1, 5]], [[2, 2], [3, 2], [0, 5], [0, 2], [4, 3]], [[4, 6], [6, 3], [5, 4], [3, 6], [1, 3]], [[5, 6], [6, 2], [1, 2], [1, 6], [2, 3]], [[0, 1], [4, 5], [3, 3], [1, 5], [5, 4]], [[2, 2], [4, 5], [4, 4], [1, 2], [5, 5]], [[5, 6], [3, 3], [3, 6], [5, 5], [1, 6]], [[2, 4], [2, 1], [3, 6], [2, 6], [0, 3]], [[4, 6], [6, 4], [3, 3], [5, 4], [4, 2]], [[4, 6], [1, 4], [0, 5], [6, 4], [4, 4]], [[4, 5], [6, 4], [5, 3], [4, 2], [6, 1]], [[5, 6], [0, 2], [3, 6], [1, 3], [1, 6]], [[6, 4], [6, 2], [5, 3], [6, 5], [1, 2]], [[4, 5], [6, 2], [1, 1], [2, 6], [5, 1]], [[2, 4], [4, 5], [1, 5], [1, 1], [5, 5]], [[1, 4], [2, 1], [6, 2], [4, 2], [2, 3]], [[1, 5], [4, 3], [4, 4], [4, 1], [0, 6]], [[0, 1], [5, 6], [4, 5], [1, 2], [5, 5]], [[0, 5], [0, 2], [1, 2], [5, 5], [0, 3]], [[2, 4], [2, 1], [1, 5], [4, 2], [6, 5]], [[5, 4], [4, 3], [1, 6], [4, 1], [6, 1]], [[5, 6], [4, 5], [1, 5], [4, 4], [2, 6]], [[5, 6], [5, 5], [1, 3], [1, 6], [5, 1]], [[2, 2], [0, 2], [5, 4], [4, 4], [1, 3]], [[6, 3], [3, 3], [1, 1], [6, 1], [0, 6]], [[5, 6], [6, 3], [3, 4], [6, 5], [0, 4]], [[2, 2], [6, 5], [4, 4], [2, 6], [2, 3]], [[3, 1], [6, 2], [3, 4], [1, 5], [4, 3]], [[2, 4], [1, 4], [4, 5], [3, 4], [5, 5]], [[4, 5], [6, 4], [0, 2], [6, 6], [6, 1]], [[5, 6], [5, 2], [3, 3], [6, 5], [6, 1]], [[2, 5], [5, 6], [6, 3], [3, 3], [1, 6]], [[2, 4], [6, 4], [6, 2], [5, 5], [5, 1]], [[3, 2], [3, 1], [6, 2], [0, 4], [2, 3]]]\n",
            "tiles_paths: [['Warsztaty-badawcze/Selected_Data/ytma49_042403_benign1_ccd/1_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign1_ccd/3_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign1_ccd/1_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign1_ccd/2_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign1_ccd/0_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_072303_benign2_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_benign2_ccd/4_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_benign2_ccd/5_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_benign2_ccd/0_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_benign2_ccd/6_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111303_benign2_ccd/2_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign2_ccd/6_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign2_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign2_ccd/4_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign2_ccd/2_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant3_ccd/4_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant3_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant3_ccd/2_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant3_ccd/3_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant3_ccd/3_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant2_ccd/0_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant2_ccd/1_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant2_ccd/4_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant2_ccd/1_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant2_ccd/1_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant1_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant1_ccd/1_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant1_ccd/5_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant1_ccd/0_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant1_ccd/6_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant2_ccd/3_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant2_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant2_ccd/3_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant2_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant2_ccd/1_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042003_benign1_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign1_ccd/4_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign1_ccd/1_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign1_ccd/1_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign1_ccd/0_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111003_benign2_ccd/4_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign2_ccd/1_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign2_ccd/2_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign2_ccd/5_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign2_ccd/5_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111003_benign3_ccd/0_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign3_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign3_ccd/5_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign3_ccd/1_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign3_ccd/4_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant3_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant3_ccd/0_2.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant3_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant3_ccd/3_6.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant3_ccd/1_2.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant3_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant3_ccd/2_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant3_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant3_ccd/5_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant3_ccd/5_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042403_benign2_ccd/2_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign2_ccd/2_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign2_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign2_ccd/5_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign2_ccd/5_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant1_ccd/0_1.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant1_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant1_ccd/4_3.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant1_ccd/3_6.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant1_ccd/1_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant1_ccd/4_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant1_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant1_ccd/1_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant1_ccd/2_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant1_ccd/5_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant1_ccd/3_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant1_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant1_ccd/0_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant1_ccd/3_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant1_ccd/3_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant1_ccd/3_4.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant1_ccd/1_1.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant1_ccd/1_2.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant1_ccd/2_6.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant1_ccd/2_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant1_ccd/4_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant1_ccd/2_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant1_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant1_ccd/5_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant1_ccd/1_2.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042403_benign3_ccd/2_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign3_ccd/3_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign3_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign3_ccd/2_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_benign3_ccd/6_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant1_ccd/3_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant1_ccd/1_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant1_ccd/3_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant1_ccd/5_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_malignant1_ccd/0_4.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042003_benign3_ccd/3_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign3_ccd/3_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign3_ccd/6_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign3_ccd/4_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign3_ccd/1_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042003_benign2_ccd/3_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign2_ccd/3_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign2_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign2_ccd/5_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_benign2_ccd/0_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma23_022103_benign2_ccd/4_6.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign2_ccd/2_5.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign2_ccd/1_4.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign2_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign2_ccd/2_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma55_030603_benign2_ccd/4_6.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign2_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign2_ccd/3_4.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign2_ccd/4_4.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign2_ccd/5_5.png'], ['Warsztaty-badawcze/Selected_Data/ytma12_010804_benign2_ccd/2_4.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign2_ccd/0_5.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign2_ccd/2_1.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign2_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign2_ccd/1_5.png'], ['Warsztaty-badawcze/Selected_Data/ytma55_030603_benign4_ccd/2_2.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign4_ccd/3_2.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign4_ccd/0_5.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign4_ccd/0_2.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign4_ccd/4_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant3_ccd/4_6.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant3_ccd/6_3.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant3_ccd/5_4.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant3_ccd/3_6.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant3_ccd/1_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant2_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant2_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant2_ccd/1_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant2_ccd/1_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant2_ccd/2_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma12_010804_benign3_ccd/0_1.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign3_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign3_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign3_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign3_ccd/5_4.png'], ['Warsztaty-badawcze/Selected_Data/ytma10_010704_benign2_ccd/2_2.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign2_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign2_ccd/4_4.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign2_ccd/1_2.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign2_ccd/5_5.png'], ['Warsztaty-badawcze/Selected_Data/ytma10_010704_benign3_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign3_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign3_ccd/3_6.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign3_ccd/5_5.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign3_ccd/1_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant2_ccd/2_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant2_ccd/2_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant2_ccd/3_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant2_ccd/2_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant2_ccd/0_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042203_benign3_ccd/4_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign3_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign3_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign3_ccd/5_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign3_ccd/4_2.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant3_ccd/4_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant3_ccd/1_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant3_ccd/0_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant3_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042403_malignant3_ccd/4_4.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant1_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant1_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant1_ccd/5_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant1_ccd/4_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_malignant1_ccd/6_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042203_benign2_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign2_ccd/0_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign2_ccd/3_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign2_ccd/1_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign2_ccd/1_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant3_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant3_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant3_ccd/5_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant3_ccd/6_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_malignant3_ccd/1_2.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111303_benign3_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign3_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign3_ccd/1_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign3_ccd/2_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign3_ccd/5_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant2_ccd/2_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant2_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant2_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant2_ccd/1_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042003_malignant2_ccd/5_5.png'], ['Warsztaty-badawcze/Selected_Data/ytma23_022103_benign3_ccd/1_4.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign3_ccd/2_1.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign3_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign3_ccd/4_2.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign3_ccd/2_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant2_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant2_ccd/4_3.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant2_ccd/4_4.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant2_ccd/4_1.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant2_ccd/0_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_042203_benign1_ccd/0_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign1_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign1_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign1_ccd/1_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_042203_benign1_ccd/5_5.png'], ['Warsztaty-badawcze/Selected_Data/ytma55_030603_benign5_ccd/0_5.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign5_ccd/0_2.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign5_ccd/1_2.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign5_ccd/5_5.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign5_ccd/0_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma12_010804_benign1_ccd/2_4.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign1_ccd/2_1.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign1_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign1_ccd/4_2.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_benign1_ccd/6_5.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111003_benign1_ccd/5_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign1_ccd/4_3.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign1_ccd/1_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign1_ccd/4_1.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111003_benign1_ccd/6_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant2_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant2_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant2_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant2_ccd/4_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant2_ccd/2_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma10_010704_benign1_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign1_ccd/5_5.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign1_ccd/1_3.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign1_ccd/1_6.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_benign1_ccd/5_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant3_ccd/2_2.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant3_ccd/0_2.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant3_ccd/5_4.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant3_ccd/4_4.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_malignant3_ccd/1_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma55_030603_benign1_ccd/6_3.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign1_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign1_ccd/1_1.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign1_ccd/6_1.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign1_ccd/0_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma23_022103_benign1_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign1_ccd/6_3.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign1_ccd/3_4.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign1_ccd/6_5.png', 'Warsztaty-badawcze/Selected_Data/ytma23_022103_benign1_ccd/0_4.png'], ['Warsztaty-badawcze/Selected_Data/ytma55_030603_benign3_ccd/2_2.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign3_ccd/6_5.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign3_ccd/4_4.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign3_ccd/2_6.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign3_ccd/2_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma55_030603_benign6_ccd/3_1.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign6_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign6_ccd/3_4.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign6_ccd/1_5.png', 'Warsztaty-badawcze/Selected_Data/ytma55_030603_benign6_ccd/4_3.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111303_benign1_ccd/2_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign1_ccd/1_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign1_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign1_ccd/3_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_benign1_ccd/5_5.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant3_ccd/4_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant3_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant3_ccd/0_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant3_ccd/6_6.png', 'Warsztaty-badawcze/Selected_Data/ytma49_111303_malignant3_ccd/6_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant1_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant1_ccd/5_2.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant1_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant1_ccd/6_5.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant1_ccd/6_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant2_ccd/2_5.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant2_ccd/5_6.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant2_ccd/6_3.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant2_ccd/3_3.png', 'Warsztaty-badawcze/Selected_Data/ytma12_010804_malignant2_ccd/1_6.png'], ['Warsztaty-badawcze/Selected_Data/ytma49_072303_benign1_ccd/2_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_benign1_ccd/6_4.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_benign1_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_benign1_ccd/5_5.png', 'Warsztaty-badawcze/Selected_Data/ytma49_072303_benign1_ccd/5_1.png'], ['Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant2_ccd/3_2.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant2_ccd/3_1.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant2_ccd/6_2.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant2_ccd/0_4.png', 'Warsztaty-badawcze/Selected_Data/ytma10_010704_malignant2_ccd/2_3.png']]\n",
            "  done\n",
            "Loading SparseConvMIL model\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "  done\n",
            "Starting training...\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   0/100     loss=0.692     bac=0.504\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   1/100     loss=0.690     bac=0.528\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   2/100     loss=0.686     bac=0.556\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   3/100     loss=0.675     bac=0.667\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   4/100     loss=0.695     bac=0.526\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   5/100     loss=0.696     bac=0.553\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   6/100     loss=0.707     bac=0.506\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   7/100     loss=0.684     bac=0.413\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   8/100     loss=0.716     bac=0.569\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch   9/100     loss=0.679     bac=0.540\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  10/100     loss=0.665     bac=0.636\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  11/100     loss=0.668     bac=0.629\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  12/100     loss=0.667     bac=0.606\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  13/100     loss=0.665     bac=0.621\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  14/100     loss=0.642     bac=0.625\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  15/100     loss=0.649     bac=0.660\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  16/100     loss=0.641     bac=0.630\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  17/100     loss=0.630     bac=0.684\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  18/100     loss=0.762     bac=0.419\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  19/100     loss=0.689     bac=0.603\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  20/100     loss=0.680     bac=0.492\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  21/100     loss=0.712     bac=0.523\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  22/100     loss=0.683     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  23/100     loss=0.684     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  24/100     loss=0.688     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  25/100     loss=0.683     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  26/100     loss=0.681     bac=0.519\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  27/100     loss=0.685     bac=0.520\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  28/100     loss=0.696     bac=0.499\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  29/100     loss=0.669     bac=0.591\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  30/100     loss=0.674     bac=0.587\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  31/100     loss=0.677     bac=0.621\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  32/100     loss=0.663     bac=0.579\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  33/100     loss=0.694     bac=0.532\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  34/100     loss=0.690     bac=0.529\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  35/100     loss=0.656     bac=0.656\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  36/100     loss=0.614     bac=0.749\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  37/100     loss=0.668     bac=0.602\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  38/100     loss=0.660     bac=0.641\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  39/100     loss=0.711     bac=0.484\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  40/100     loss=0.684     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  41/100     loss=0.674     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  42/100     loss=0.655     bac=0.565\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  43/100     loss=0.648     bac=0.588\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  44/100     loss=0.662     bac=0.584\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  45/100     loss=0.662     bac=0.588\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  46/100     loss=0.691     bac=0.559\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  47/100     loss=0.607     bac=0.668\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  48/100     loss=0.618     bac=0.630\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  49/100     loss=0.672     bac=0.523\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  50/100     loss=0.717     bac=0.513\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  51/100     loss=0.691     bac=0.504\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  52/100     loss=0.663     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  53/100     loss=0.672     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  54/100     loss=0.674     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  55/100     loss=0.671     bac=0.577\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  56/100     loss=0.625     bac=0.615\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  57/100     loss=0.653     bac=0.656\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  58/100     loss=0.602     bac=0.660\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  59/100     loss=0.606     bac=0.625\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  60/100     loss=0.710     bac=0.555\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  61/100     loss=0.748     bac=0.412\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  62/100     loss=0.741     bac=0.312\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  63/100     loss=0.696     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  64/100     loss=0.693     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  65/100     loss=0.691     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  66/100     loss=0.688     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  67/100     loss=0.686     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  68/100     loss=0.686     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  69/100     loss=0.688     bac=0.523\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  70/100     loss=0.661     bac=0.603\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  71/100     loss=0.651     bac=0.583\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  72/100     loss=0.643     bac=0.698\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  73/100     loss=0.651     bac=0.672\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  74/100     loss=0.710     bac=0.511\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  75/100     loss=0.691     bac=0.550\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  76/100     loss=0.645     bac=0.695\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  77/100     loss=0.675     bac=0.614\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  78/100     loss=0.679     bac=0.560\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  79/100     loss=0.650     bac=0.645\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  80/100     loss=0.684     bac=0.556\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  81/100     loss=0.622     bac=0.703\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  82/100     loss=0.632     bac=0.641\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  83/100     loss=0.645     bac=0.572\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  84/100     loss=0.634     bac=0.611\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  85/100     loss=0.624     bac=0.614\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  86/100     loss=0.691     bac=0.546\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  87/100     loss=0.697     bac=0.469\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  88/100     loss=0.695     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  89/100     loss=0.688     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  90/100     loss=0.682     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  91/100     loss=0.675     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  92/100     loss=0.677     bac=0.500\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  93/100     loss=0.665     bac=0.549\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  94/100     loss=0.661     bac=0.644\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  95/100     loss=0.680     bac=0.594\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  96/100     loss=0.672     bac=0.576\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  97/100     loss=0.685     bac=0.530\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  98/100     loss=0.663     bac=0.504\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch  99/100     loss=0.666     bac=0.558\n",
            "  done\n",
            "Epoch data saved to Warsztaty-badawcze/train_epochs.csv\n"
          ]
        }
      ]
    }
  ]
}